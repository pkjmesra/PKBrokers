# """
#     The MIT License (MIT)

#     Copyright (c) 2023 pkjmesra

#     Permission is hereby granted, free of charge, to any person obtaining a copy
#     of this software and associated documentation files (the "Software"), to deal
#     in the Software without restriction, including without limitation the rights
#     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#     copies of the Software, and to permit persons to whom the Software is
#     furnished to do so, subject to the following conditions:

#     The above copyright notice and this permission notice shall be included in all
#     copies or substantial portions of the Software.

#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#     SOFTWARE.

# """

name: 1. History Data Child
on:
  workflow_dispatch:  # Allow manual triggering
    inputs:
      logLevel:
        description: 'Log level for PKDevTools (default 20)'
        required: false
        default: 20
        type: number
      period:
        description: 'Specific period to run (default: day)'
        required: false
        default: 'day'
        type: string
      kiteToken:
        description: 'Kite API token'
        required: false
        type: string
      pastoffset:
        description: 'Past number of days for which data has to be fetched'
        required: false
        default: 0
        type: number

jobs:
  historical-data:
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
      TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
    steps:

    - name: Mask sensitive outputs
      run: |
        # Mask the token output from inputs
        echo "::add-mask::${{ inputs.kiteToken || secrets.KTOKEN }}"

    - name: Checkout PKBrokers code
      uses: actions/checkout@v4
      with:
        repository: pkjmesra/PKBrokers
        ref: main

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: pip install -e . kiteconnect

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Create session file
      run: |
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session

    - name: Calculate missing trading days
      id: calc_offset
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        # If pastoffset is provided and > 0, use it
        INPUT_OFFSET=${{ inputs.pastoffset || 0 }}
        
        if [ "$INPUT_OFFSET" -gt 0 ]; then
          echo "Using provided pastoffset: $INPUT_OFFSET"
          echo "PAST_OFFSET=$INPUT_OFFSET" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Calculate missing trading days using the unified pkl generator script
        echo "Calculating missing trading days..."
        
        # Use generate_pkl_from_ticks.py which already has this logic
        # It will download pkl, check dates, and we can capture the missing days
        CALCULATED_OFFSET=$(python3 -c "
        import sys, pickle, requests
        from datetime import datetime, timedelta
        DEFAULT = 5
        try:
            from PKDevTools.classes.PKDateUtilities import PKDateUtilities
            urls = [
                'https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/actions-data-download/stock_data_23122025.pkl',
                'https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/actions-data-download/stock_data_17122025.pkl',
            ]
            data = None
            for url in urls:
                try:
                    r = requests.get(url, timeout=60)
                    if r.status_code == 200 and len(r.content) > 1000000:
                        data = pickle.loads(r.content)
                        if len(data) > 100:
                            print(f'Found pkl: {len(data)} instruments', file=sys.stderr)
                            break
                except: continue
            if not data:
                print(DEFAULT)
                sys.exit(0)
            latest = None
            for s, df in list(data.items())[:50]:
                try:
                    if hasattr(df, 'index') and len(df) > 0:
                        m = df.index.max()
                        if hasattr(m, 'date'): m = m.date()
                        if latest is None or m > latest: latest = m
                except: continue
            if not latest:
                print(DEFAULT)
                sys.exit(0)
            print(f'Latest date: {latest}', file=sys.stderr)
            lt = PKDateUtilities.tradingDate()
            if hasattr(lt, 'date'): lt = lt.date()
            print(f'Last trading: {lt}', file=sys.stderr)
            if latest >= lt:
                print(0)
                sys.exit(0)
            try:
                missing = PKDateUtilities.trading_days_between(latest, lt)
                print(f'Missing trading days: {missing}', file=sys.stderr)
                print(max(1, missing))
            except:
                diff = (lt - latest).days
                print(max(1, int(diff * 5 / 7)))
        except Exception as e:
            print(f'Error: {e}', file=sys.stderr)
            print(DEFAULT)
        " 2>&1 | tee /dev/stderr | tail -1)
        
        # Ensure we have a valid number
        if [ -z "$CALCULATED_OFFSET" ] || ! [[ "$CALCULATED_OFFSET" =~ ^[0-9]+$ ]]; then
          echo "Invalid offset '$CALCULATED_OFFSET', using default 5"
          CALCULATED_OFFSET=5
        fi
        
        echo "Calculated pastoffset: $CALCULATED_OFFSET"
        echo "PAST_OFFSET=$CALCULATED_OFFSET" >> $GITHUB_OUTPUT

    - name: Run historical data for ${{ inputs.period }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        
        # Use calculated offset from previous step if available
        OFFSET=${{ steps.calc_offset.outputs.PAST_OFFSET || inputs.pastoffset || 0 }}
        echo "Running pkkite with --history=${{ inputs.period }} --pastoffset=$OFFSET"
        
        python pkkite.py --history=${{ inputs.period }} --pastoffset=$OFFSET --verbose

    - name: Export database to pkl files using unified generator
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        echo "Using unified pkl generator script (--from-db mode)..."
        
        # Use the unified generate_pkl_from_ticks.py script with --from-db flag
        python3 ../../../pkbrokers/scripts/generate_pkl_from_ticks.py \
          --from-db \
          --data-dir results/Data \
          --verbose
        
        echo ""
        echo "Generated pkl files:"
        ls -la results/Data/*.pkl 2>/dev/null || echo "No pkl files found"

    - name: Commit updated pkl file to PKScreener actions-data-download
      env:
        CI_PAT: ${{ secrets.CI_PAT }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Clone PKScreener actions-data-download branch
        git clone --single-branch --branch actions-data-download https://x-access-token:$CI_PAT@github.com/pkjmesra/PKScreener.git pkscreener-data
        cd pkscreener-data
        
        # Get today's date in DDMMYYYY format
        TODAY=$(date +%d%m%Y)
        PERIOD="${{ inputs.period }}"
        
        echo "Period: $PERIOD"
        echo "Today's suffix: $TODAY"
        
        # Determine pkl filename based on period
        # day -> stock_data_DDMMYYYY.pkl
        # minute (1-min) -> intraday_stock_data_DDMMYYYY.pkl
        # 5minute -> intraday_stock_data_DDMMYYYY_5min.pkl
        # 10minute -> intraday_stock_data_DDMMYYYY_10min.pkl
        # 30minute -> intraday_stock_data_DDMMYYYY_30min.pkl
        # 60minute -> intraday_stock_data_DDMMYYYY_60min.pkl
        
        case "$PERIOD" in
            "day")
                TARGET_FILE="stock_data_${TODAY}.pkl"
                GENERIC_FILE="daily_candles.pkl"
                MIN_SIZE=1000000  # 1 MB minimum for daily
                ;;
            "minute")
                TARGET_FILE="intraday_stock_data_${TODAY}.pkl"
                GENERIC_FILE="intraday_1m_candles.pkl"
                MIN_SIZE=10000  # 10 KB minimum for intraday
                ;;
            "5minute")
                TARGET_FILE="intraday_stock_data_${TODAY}_5min.pkl"
                GENERIC_FILE="intraday_5m_candles.pkl"
                MIN_SIZE=10000
                ;;
            "10minute")
                TARGET_FILE="intraday_stock_data_${TODAY}_10min.pkl"
                GENERIC_FILE="intraday_10m_candles.pkl"
                MIN_SIZE=10000
                ;;
            "30minute")
                TARGET_FILE="intraday_stock_data_${TODAY}_30min.pkl"
                GENERIC_FILE="intraday_30m_candles.pkl"
                MIN_SIZE=10000
                ;;
            "60minute")
                TARGET_FILE="intraday_stock_data_${TODAY}_60min.pkl"
                GENERIC_FILE="intraday_60m_candles.pkl"
                MIN_SIZE=10000
                ;;
            *)
                echo "Unknown period: $PERIOD, skipping pkl commit"
                exit 0
                ;;
        esac
        
        echo "Target file: $TARGET_FILE"
        echo "Generic file: $GENERIC_FILE"
        
        # List available files
        echo "Files in ../pkbrokers/kite/examples/results/Data/:"
        ls -la ../pkbrokers/kite/examples/results/Data/ 2>/dev/null || echo "Directory not found"
        
        FILES_COPIED=0
        
        if [ "$PERIOD" = "day" ]; then
            # Daily pkl files
            for PKL_FILE in ../pkbrokers/kite/examples/results/Data/stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/daily_candles.pkl; do
              if [ -f "$PKL_FILE" ]; then
                PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
                if [ "$PKL_SIZE" -gt "$MIN_SIZE" ]; then
                  echo "✅ Found: $PKL_FILE ($PKL_SIZE bytes)"
                  cp "$PKL_FILE" actions-data-download/$TARGET_FILE
                  cp "$PKL_FILE" actions-data-download/$GENERIC_FILE
                  FILES_COPIED=$((FILES_COPIED + 1))
                  break
                else
                  echo "⚠️ File too small: $PKL_FILE ($PKL_SIZE bytes)"
                fi
              fi
            done
            
            # Also try to commit intraday from ticks.json for day period
            INTRADAY_FOUND=0
            for PKL_FILE in ../pkbrokers/kite/examples/results/Data/intraday_stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/intraday_1m_candles.pkl; do
              if [ -f "$PKL_FILE" ]; then
                PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
                if [ "$PKL_SIZE" -gt 10000 ]; then
                  echo "✅ Found intraday: $PKL_FILE ($PKL_SIZE bytes)"
                  cp "$PKL_FILE" actions-data-download/intraday_stock_data_${TODAY}.pkl
                  cp "$PKL_FILE" actions-data-download/intraday_1m_candles.pkl
                  FILES_COPIED=$((FILES_COPIED + 1))
                  INTRADAY_FOUND=1
                  break
                fi
              fi
            done
            
            # If no intraday pkl, try to generate from ticks.json
            if [ "$INTRADAY_FOUND" -eq 0 ]; then
              echo "No intraday pkl found, trying to generate from ticks.json..."
              cd ../pkbrokers/kite/examples/
              python3 ../../../pkbrokers/scripts/generate_pkl_from_ticks.py --data-dir results/Data --verbose 2>/dev/null || true
              cd -
              
              for PKL_FILE in ../pkbrokers/kite/examples/results/Data/intraday_stock_data_*.pkl; do
                if [ -f "$PKL_FILE" ]; then
                  PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
                  if [ "$PKL_SIZE" -gt 10000 ]; then
                    echo "✅ Generated intraday: $PKL_FILE ($PKL_SIZE bytes)"
                    cp "$PKL_FILE" actions-data-download/intraday_stock_data_${TODAY}.pkl
                    cp "$PKL_FILE" actions-data-download/intraday_1m_candles.pkl
                    FILES_COPIED=$((FILES_COPIED + 1))
                    break
                  fi
                fi
              done
            fi
        else
            # Intraday periods (minute, 5minute, 10minute, etc.)
            # Look for the history database file generated by pkkite
            for PKL_FILE in ../pkbrokers/kite/examples/results/Data/*.pkl; do
              if [ -f "$PKL_FILE" ]; then
                PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
                if [ "$PKL_SIZE" -gt "$MIN_SIZE" ]; then
                  echo "✅ Found: $PKL_FILE ($PKL_SIZE bytes)"
                  cp "$PKL_FILE" actions-data-download/$TARGET_FILE
                  cp "$PKL_FILE" actions-data-download/$GENERIC_FILE
                  FILES_COPIED=$((FILES_COPIED + 1))
                  break
                fi
              fi
            done
        fi
        
        # DO NOT copy .db files - they are too large for GitHub (>100MB limit)
        echo "Note: SQLite .db files are not committed (too large for GitHub)"
        
        echo "Total files copied: $FILES_COPIED"
        
        if [ "$FILES_COPIED" -eq 0 ]; then
          echo "⚠️ No pkl files found to commit for period: $PERIOD"
          exit 0
        fi
        
        # Commit and push
        git config user.name "github-actions[bot]"
        git config user.email "actions@github.com"
        
        # Remove any .db files that may have been accidentally copied (too large for GitHub)
        rm -f actions-data-download/*.db 2>/dev/null || true
        
        # Only add pkl and json files (no .db files - they exceed GitHub's 100MB limit)
        git add -f actions-data-download/*.pkl 2>/dev/null || true
        git add -f actions-data-download/*.json 2>/dev/null || true
        
        # Show what's staged
        echo "Files to be committed:"
        git diff --staged --name-only
        
        if ! git diff --staged --quiet; then
          git commit -m "Update $TARGET_FILE from history download - $TODAY [period: $PERIOD]"
          
          # Retry push with rebase if needed
          for i in 1 2 3; do
            if git push; then
              echo "✅ Successfully committed updated pkl files to PKScreener actions-data-download"
              break
            else
              echo "Push failed, attempt $i, pulling and retrying..."
              git pull --rebase origin actions-data-download || true
              sleep 2
            fi
          done
        else
          echo "No changes to commit"
        fi

    - name: Send notification about the completion
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ inputs.period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully finished child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

  trigger-next-child-job:
    needs: [historical-data]
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Determine next period
      id: next-period
      run: |
        CURRENT_PERIOD="${{ github.event.inputs.period }}"
        echo "Current period: $CURRENT_PERIOD"
        
        # Only run for two intervals: day and minute (1-min)
        # Other intervals (5minute, 10minute, 30minute, 60minute) are skipped
        case "$CURRENT_PERIOD" in
            "day")
                NEXT_PERIOD="minute"
                ;;
            "minute")
                # Stop after minute - don't cascade to other intervals
                echo "✅ All periods completed (day and minute). Exiting."
                echo "should_exit=true" >> $GITHUB_OUTPUT
                exit 0
                ;;
            *)
                # Default to starting from day if no period specified
                NEXT_PERIOD="day"
                ;;
        esac
        
        echo "Next period: $NEXT_PERIOD"
        echo "next_period=$NEXT_PERIOD" >> $GITHUB_OUTPUT
        echo "should_exit=false" >> $GITHUB_OUTPUT

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Exit if all periods completed
      if: steps.next-period.outputs.should_exit == 'true'
      run: |
        echo "✅ All periods have been processed. Workflow completed."
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        pip install pkdevtools
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ All periods for historical data jobs have been processed. Workflow completed.');"
        exit 0

    - name: Trigger next child job
      if: steps.next-period.outputs.should_exit == 'false'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
      run: |
        NEXT_PERIOD="${{ steps.next-period.outputs.next_period }}"
        echo "Triggering next child job for period: $NEXT_PERIOD"
        
        LOG_LEVEL="${{ github.event.inputs.logLevel || '20' }}"
        KITE_TOKEN="${{ github.event.inputs.kiteToken || secrets.KTOKEN }}"
        
        # Trigger child workflow for the next period only
        curl -X POST \
          -H "Authorization: token $GITHUB_TOKEN" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/actions/workflows/w1-workflow-history-data-child.yml/dispatches" \
          -d "{\"ref\":\"main\",\"inputs\":{\"period\":\"$NEXT_PERIOD\",\"logLevel\":\"$LOG_LEVEL\",\"kiteToken\":\"$KITE_TOKEN\",\"pastoffset\":\"${{ github.event.inputs.pastoffset || 0 }}\"}}"
        
        echo "✅ Successfully triggered next child job for period: $NEXT_PERIOD"

    - name: Send notification about the trigger
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ steps.next-period.outputs.next_period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        pip install pkdevtools
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully triggered child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

    - name: Log completion
      run: |
        echo "Next period job triggered successfully. Workflow will continue with the next period in the chain."
