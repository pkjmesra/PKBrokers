# """
#     The MIT License (MIT)

#     Copyright (c) 2023 pkjmesra

#     Permission is hereby granted, free of charge, to any person obtaining a copy
#     of this software and associated documentation files (the "Software"), to deal
#     in the Software without restriction, including without limitation the rights
#     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#     copies of the Software, and to permit persons to whom the Software is
#     furnished to do so, subject to the following conditions:

#     The above copyright notice and this permission notice shall be included in all
#     copies or substantial portions of the Software.

#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#     SOFTWARE.

# """

name: 1. History Data Child
on:
  workflow_dispatch:  # Allow manual triggering
    inputs:
      logLevel:
        description: 'Log level for PKDevTools (default 20)'
        required: false
        default: 20
        type: number
      period:
        description: 'Specific period to run (default: day)'
        required: false
        default: 'day'
        type: string
      kiteToken:
        description: 'Kite API token'
        required: false
        type: string
      pastoffset:
        description: 'Past number of days for which data has to be fetched'
        required: false
        default: 0
        type: number

jobs:
  historical-data:
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
      TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
    steps:

    - name: Mask sensitive outputs
      run: |
        # Mask the token output from inputs
        echo "::add-mask::${{ inputs.kiteToken || secrets.KTOKEN }}"

    - name: Checkout PKBrokers code
      uses: actions/checkout@v4
      with:
        repository: pkjmesra/PKBrokers
        ref: main

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: pip install -e . kiteconnect

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Create session file
      run: |
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session

    - name: Calculate missing trading days
      id: calc_offset
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        # Calculate the correct pastoffset by checking existing pkl file
        PAST_OFFSET=${{ inputs.pastoffset || 0 }}
        
        python3 << 'CALC_SCRIPT'
        import os
        import sys
        import pickle
        import requests
        from datetime import datetime, timedelta
        import pandas as pd
        
        def get_missing_days():
            """Calculate missing trading days from the latest pkl file."""
            try:
                from PKDevTools.classes.PKDateUtilities import PKDateUtilities
                
                # Try to download existing pkl from GitHub
                base_urls = [
                    "https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/actions-data-download/",
                    "https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/results/Data/",
                ]
                
                today = datetime.now()
                data = None
                
                for days_back in range(10):
                    check_date = today - timedelta(days=days_back)
                    for base_url in base_urls:
                        for fmt in ['%d%m%Y', '%d%m%y']:
                            url = f"{base_url}stock_data_{check_date.strftime(fmt)}.pkl"
                            try:
                                response = requests.get(url, timeout=30)
                                if response.status_code == 200 and len(response.content) > 1000000:
                                    data = pickle.loads(response.content)
                                    if isinstance(data, dict) and len(data) > 100:
                                        print(f"Found pkl with {len(data)} instruments", file=sys.stderr)
                                        break
                            except:
                                continue
                        if data:
                            break
                    if data:
                        break
                
                if not data:
                    print("5")  # Default to 5 days if no pkl found
                    return
                
                # Find latest date in data
                latest_date = None
                for symbol, df in list(data.items())[:50]:
                    try:
                        if hasattr(df, 'index') and len(df) > 0:
                            max_date = df.index.max()
                            if hasattr(max_date, 'date'):
                                max_date = max_date.date()
                            if latest_date is None or max_date > latest_date:
                                latest_date = max_date
                    except:
                        continue
                
                if latest_date is None:
                    print("5")
                    return
                
                # Get last trading date
                last_trading = PKDateUtilities.tradingDate()
                if hasattr(last_trading, 'date'):
                    last_trading = last_trading.date()
                
                if latest_date >= last_trading:
                    print("0")  # Data is fresh
                    return
                
                # Calculate missing days
                try:
                    missing = PKDateUtilities.trading_days_between(latest_date, last_trading)
                    print(str(max(1, missing)))
                except:
                    diff = (last_trading - latest_date).days
                    print(str(max(1, diff // 2)))
                    
            except Exception as e:
                print(f"Error: {e}", file=sys.stderr)
                print("5")  # Default
        
        get_missing_days()
        CALC_SCRIPT
        
        CALCULATED_OFFSET=$(python3 -c "
        import os, sys, pickle, requests
        from datetime import datetime, timedelta
        try:
            from PKDevTools.classes.PKDateUtilities import PKDateUtilities
            today = datetime.now()
            data = None
            for days_back in range(10):
                check_date = today - timedelta(days=days_back)
                for base_url in ['https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/actions-data-download/', 'https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/results/Data/']:
                    for fmt in ['%d%m%Y', '%d%m%y']:
                        try:
                            r = requests.get(f'{base_url}stock_data_{check_date.strftime(fmt)}.pkl', timeout=30)
                            if r.status_code == 200 and len(r.content) > 1000000:
                                data = pickle.loads(r.content)
                                if len(data) > 100: break
                        except: continue
                    if data: break
                if data: break
            if not data: print(5); sys.exit(0)
            latest = None
            for s, df in list(data.items())[:50]:
                try:
                    if hasattr(df, 'index') and len(df) > 0:
                        m = df.index.max()
                        if hasattr(m, 'date'): m = m.date()
                        if latest is None or m > latest: latest = m
                except: continue
            if not latest: print(5); sys.exit(0)
            lt = PKDateUtilities.tradingDate()
            if hasattr(lt, 'date'): lt = lt.date()
            if latest >= lt: print(0); sys.exit(0)
            try: print(max(1, PKDateUtilities.trading_days_between(latest, lt)))
            except: print(max(1, (lt - latest).days // 2))
        except Exception as e: print(5)
        ")
        
        # Use calculated offset if input is 0
        if [ "$PAST_OFFSET" -eq 0 ]; then
          PAST_OFFSET=$CALCULATED_OFFSET
        fi
        
        echo "Calculated pastoffset: $PAST_OFFSET"
        echo "PAST_OFFSET=$PAST_OFFSET" >> $GITHUB_OUTPUT

    - name: Run historical data for ${{ inputs.period }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        
        # Use calculated offset from previous step if available
        OFFSET=${{ steps.calc_offset.outputs.PAST_OFFSET || inputs.pastoffset || 0 }}
        echo "Running pkkite with --history=${{ inputs.period }} --pastoffset=$OFFSET"
        
        python pkkite.py --history=${{ inputs.period }} --pastoffset=$OFFSET --verbose

    - name: Export database to pkl files using unified generator
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        echo "Using unified pkl generator script (--from-db mode)..."
        
        # Use the unified generate_pkl_from_ticks.py script with --from-db flag
        python3 ../../../pkbrokers/scripts/generate_pkl_from_ticks.py \
          --from-db \
          --data-dir results/Data \
          --verbose
        
        echo ""
        echo "Generated pkl files:"
        ls -la results/Data/*.pkl 2>/dev/null || echo "No pkl files found"

    - name: Commit updated pkl file to PKScreener actions-data-download
      if: inputs.period == 'day'
      env:
        CI_PAT: ${{ secrets.CI_PAT }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Clone PKScreener actions-data-download branch
        git clone --single-branch --branch actions-data-download https://x-access-token:$CI_PAT@github.com/pkjmesra/PKScreener.git pkscreener-data
        cd pkscreener-data
        
        # Get today's date in DDMMYYYY format
        TODAY=$(date +%d%m%Y)
        
        echo "Looking for pkl files to copy..."
        echo "Today's suffix: $TODAY"
        
        # List available files
        echo "Files in ../pkbrokers/kite/examples/results/Data/:"
        ls -la ../pkbrokers/kite/examples/results/Data/ 2>/dev/null || echo "Directory not found"
        
        # Copy pkl files - try both date-suffixed and generic names
        FILES_COPIED=0
        
        # Daily pkl files
        for PKL_FILE in ../pkbrokers/kite/examples/results/Data/stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/daily_candles.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
            if [ "$PKL_SIZE" -gt 1000000 ]; then
              echo "✅ Found: $PKL_FILE ($PKL_SIZE bytes)"
              cp "$PKL_FILE" actions-data-download/stock_data_${TODAY}.pkl
              cp "$PKL_FILE" actions-data-download/daily_candles.pkl
              FILES_COPIED=$((FILES_COPIED + 1))
              break
            else
              echo "⚠️ File too small: $PKL_FILE ($PKL_SIZE bytes)"
            fi
          fi
        done
        
        # Intraday pkl files
        for PKL_FILE in ../pkbrokers/kite/examples/results/Data/intraday_stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/intraday_1m_candles.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
            if [ "$PKL_SIZE" -gt 1000 ]; then
              echo "✅ Found: $PKL_FILE ($PKL_SIZE bytes)"
              cp "$PKL_FILE" actions-data-download/intraday_stock_data_${TODAY}.pkl
              cp "$PKL_FILE" actions-data-download/intraday_1m_candles.pkl
              FILES_COPIED=$((FILES_COPIED + 1))
              break
            fi
          fi
        done
        
        # Copy any database files
        cp ../pkbrokers/kite/examples/results/Data/*.db actions-data-download/ 2>/dev/null || true
        
        echo "Total files copied: $FILES_COPIED"
        
        # Commit and push
        git config user.name "github-actions[bot]"
        git config user.email "actions@github.com"
        # Use -f to force add files that may be in .gitignore
        git add -f actions-data-download/ 2>/dev/null || true
        
        if ! git diff --staged --quiet; then
          git commit -m "Update pkl files from history download - $TODAY [period: ${{ inputs.period }}]"
          git push
          echo "✅ Successfully committed updated pkl files to PKScreener actions-data-download"
        else
          echo "No changes to commit"
        fi

    - name: Send notification about the completion
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ inputs.period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully finished child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

  trigger-next-child-job:
    needs: [historical-data]
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Determine next period
      id: next-period
      run: |
        CURRENT_PERIOD="${{ github.event.inputs.period }}"
        echo "Current period: $CURRENT_PERIOD"
        
        case "$CURRENT_PERIOD" in
            "day")
                NEXT_PERIOD="minute"
                ;;
            "minute")
                NEXT_PERIOD="5minute"
                ;;
            "5minute")
                NEXT_PERIOD="10minute"
                ;;
            "10minute")
                NEXT_PERIOD="30minute"
                ;;
            "30minute")
                NEXT_PERIOD="60minute"
                ;;
            "60minute")
                echo "✅ All periods completed. Exiting."
                echo "should_exit=true" >> $GITHUB_OUTPUT
                exit 0
                ;;
            *)
                # Default to starting from day if no period specified
                NEXT_PERIOD="day"
                ;;
        esac
        
        echo "Next period: $NEXT_PERIOD"
        echo "next_period=$NEXT_PERIOD" >> $GITHUB_OUTPUT
        echo "should_exit=false" >> $GITHUB_OUTPUT

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Exit if all periods completed
      if: steps.next-period.outputs.should_exit == 'true'
      run: |
        echo "✅ All periods have been processed. Workflow completed."
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        pip install pkdevtools
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ All periods for historical data jobs have been processed. Workflow completed.');"
        exit 0

    - name: Trigger next child job
      if: steps.next-period.outputs.should_exit == 'false'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
      run: |
        NEXT_PERIOD="${{ steps.next-period.outputs.next_period }}"
        echo "Triggering next child job for period: $NEXT_PERIOD"
        
        LOG_LEVEL="${{ github.event.inputs.logLevel || '20' }}"
        KITE_TOKEN="${{ github.event.inputs.kiteToken || secrets.KTOKEN }}"
        
        # Trigger child workflow for the next period only
        curl -X POST \
          -H "Authorization: token $GITHUB_TOKEN" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/actions/workflows/w1-workflow-history-data-child.yml/dispatches" \
          -d "{\"ref\":\"main\",\"inputs\":{\"period\":\"$NEXT_PERIOD\",\"logLevel\":\"$LOG_LEVEL\",\"kiteToken\":\"$KITE_TOKEN\",\"pastoffset\":\"${{ github.event.inputs.pastoffset || 0 }}\"}}"
        
        echo "✅ Successfully triggered next child job for period: $NEXT_PERIOD"

    - name: Send notification about the trigger
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ steps.next-period.outputs.next_period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        pip install pkdevtools
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully triggered child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

    - name: Log completion
      run: |
        echo "Next period job triggered successfully. Workflow will continue with the next period in the chain."
