# """
#     The MIT License (MIT)

#     Copyright (c) 2023 pkjmesra

#     Permission is hereby granted, free of charge, to any person obtaining a copy
#     of this software and associated documentation files (the "Software"), to deal
#     in the Software without restriction, including without limitation the rights
#     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#     copies of the Software, and to permit persons to whom the Software is
#     furnished to do so, subject to the following conditions:

#     The above copyright notice and this permission notice shall be included in all
#     copies or substantial portions of the Software.

#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#     SOFTWARE.

# """

name: 1. History Data Child
on:
  workflow_dispatch:  # Allow manual triggering
    inputs:
      logLevel:
        description: 'Log level for PKDevTools (default 20)'
        required: false
        default: 20
        type: number
      period:
        description: 'Specific period to run (default: day)'
        required: false
        default: 'day'
        type: string
      kiteToken:
        description: 'Kite API token'
        required: false
        type: string
      pastoffset:
        description: 'Past number of days for which data has to be fetched'
        required: false
        default: 0
        type: number

jobs:
  historical-data:
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
      TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
    steps:

    - name: Mask sensitive outputs
      run: |
        # Mask the token output from inputs
        echo "::add-mask::${{ inputs.kiteToken || secrets.KTOKEN }}"

    - name: Checkout PKBrokers code
      uses: actions/checkout@v4
      with:
        repository: pkjmesra/PKBrokers
        ref: main

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: pip install -e . kiteconnect

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Create session file
      run: |
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session

    - name: Calculate missing trading days
      id: calc_offset
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        # If pastoffset is provided and > 0, use it
        INPUT_OFFSET=${{ inputs.pastoffset || 0 }}
        
        if [ "$INPUT_OFFSET" -gt 0 ]; then
          echo "Using provided pastoffset: $INPUT_OFFSET"
          echo "PAST_OFFSET=$INPUT_OFFSET" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Calculate the correct pastoffset by checking existing pkl file
        echo "Calculating missing trading days from existing pkl files..."
        
        CALCULATED_OFFSET=$(python3 << 'EOF'
import sys
import pickle
import requests
from datetime import datetime, timedelta

def calculate():
    # Default if anything fails
    DEFAULT = 5
    
    # Try to find a recent large pkl file
    base_urls = [
        "https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/actions-data-download/",
        "https://raw.githubusercontent.com/pkjmesra/PKScreener/actions-data-download/results/Data/",
    ]
    
    today = datetime.now()
    data = None
    found_url = None
    
    # Search for pkl files from recent dates
    # First pass: look for large pkl files (>10MB - proper historical data)
    # Second pass: accept smaller files if no large ones found
    for min_size in [10000000, 100000]:  # 10MB, then 100KB
        for days_back in range(15):
            check_date = today - timedelta(days=days_back)
            for base_url in base_urls:
                for fmt in ['%d%m%Y', '%d%m%y']:
                    url = f"{base_url}stock_data_{check_date.strftime(fmt)}.pkl"
                    try:
                        r = requests.get(url, timeout=60)
                        if r.status_code == 200 and len(r.content) > min_size:
                            data = pickle.loads(r.content)
                            if isinstance(data, dict) and len(data) > 50:
                                found_url = url
                                print(f"Found: {url} ({len(r.content)/1024/1024:.1f}MB, {len(data)} instruments)", file=sys.stderr)
                                break
                    except Exception as e:
                        continue
                if data:
                    break
            if data:
                break
        if data:
            break
    
    if not data:
        print(f"No pkl file found, using default: {DEFAULT}", file=sys.stderr)
        print(DEFAULT)
        return
    
    # Find the latest date in the data
    latest_date = None
    for symbol, df in list(data.items())[:100]:
        try:
            if hasattr(df, 'index') and len(df) > 0:
                max_date = df.index.max()
                if hasattr(max_date, 'date'):
                    max_date = max_date.date()
                elif hasattr(max_date, 'to_pydatetime'):
                    max_date = max_date.to_pydatetime().date()
                if latest_date is None or max_date > latest_date:
                    latest_date = max_date
        except:
            continue
    
    if latest_date is None:
        print(f"Could not find latest date, using default: {DEFAULT}", file=sys.stderr)
        print(DEFAULT)
        return
    
    print(f"Latest date in pkl: {latest_date}", file=sys.stderr)
    
    # Get the last trading date
    try:
        from PKDevTools.classes.PKDateUtilities import PKDateUtilities
        last_trading = PKDateUtilities.tradingDate()
        if hasattr(last_trading, 'date'):
            last_trading = last_trading.date()
        print(f"Last trading date: {last_trading}", file=sys.stderr)
    except Exception as e:
        print(f"PKDateUtilities error: {e}, using today", file=sys.stderr)
        last_trading = today.date()
    
    # If data is fresh (up to date)
    if latest_date >= last_trading:
        print("Data is fresh!", file=sys.stderr)
        print(0)
        return
    
    # Calculate missing trading days using PKDateUtilities
    try:
        # Use PKDateUtilities to get accurate trading days count
        missing = PKDateUtilities.trading_days_between(latest_date, last_trading)
        print(f"Missing trading days (PKDateUtilities): {missing}", file=sys.stderr)
        result = max(1, missing)
    except Exception as e:
        print(f"trading_days_between error: {e}", file=sys.stderr)
        try:
            # Alternative: count trading days manually
            from PKDevTools.classes.PKDateUtilities import PKDateUtilities
            count = 0
            check = latest_date + timedelta(days=1)
            while check <= last_trading:
                # Check if it's a trading day (not weekend, not holiday)
                if PKDateUtilities.isTradingTime() or check.weekday() < 5:
                    # Additional check for holidays would be ideal
                    count += 1
                check += timedelta(days=1)
            result = max(1, count)
            print(f"Manual count of days: {result}", file=sys.stderr)
        except:
            # Last fallback: ~5 trading days per 7 calendar days
            diff = (last_trading - latest_date).days
            result = max(1, int(diff * 5 / 7))
            print(f"Fallback estimated days: {result}", file=sys.stderr)
    
    print(result)

calculate()
EOF
        )
        
        # Ensure we have a valid number, default to 5 if empty or invalid
        if [ -z "$CALCULATED_OFFSET" ] || ! [[ "$CALCULATED_OFFSET" =~ ^[0-9]+$ ]]; then
          echo "Invalid calculated offset '$CALCULATED_OFFSET', using default 5"
          CALCULATED_OFFSET=5
        fi
        
        echo "Calculated pastoffset: $CALCULATED_OFFSET"
        echo "PAST_OFFSET=$CALCULATED_OFFSET" >> $GITHUB_OUTPUT

    - name: Run historical data for ${{ inputs.period }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        
        # Use calculated offset from previous step if available
        OFFSET=${{ steps.calc_offset.outputs.PAST_OFFSET || inputs.pastoffset || 0 }}
        echo "Running pkkite with --history=${{ inputs.period }} --pastoffset=$OFFSET"
        
        python pkkite.py --history=${{ inputs.period }} --pastoffset=$OFFSET --verbose

    - name: Export database to pkl files using unified generator
      if: inputs.period == 'day'
      run: |
        cd pkbrokers/kite/examples/
        mkdir -p results/Data
        
        echo "Using unified pkl generator script (--from-db mode)..."
        
        # Use the unified generate_pkl_from_ticks.py script with --from-db flag
        python3 ../../../pkbrokers/scripts/generate_pkl_from_ticks.py \
          --from-db \
          --data-dir results/Data \
          --verbose
        
        echo ""
        echo "Generated pkl files:"
        ls -la results/Data/*.pkl 2>/dev/null || echo "No pkl files found"

    - name: Commit updated pkl file to PKScreener actions-data-download
      if: inputs.period == 'day'
      env:
        CI_PAT: ${{ secrets.CI_PAT }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Clone PKScreener actions-data-download branch
        git clone --single-branch --branch actions-data-download https://x-access-token:$CI_PAT@github.com/pkjmesra/PKScreener.git pkscreener-data
        cd pkscreener-data
        
        # Get today's date in DDMMYYYY format
        TODAY=$(date +%d%m%Y)
        
        echo "Looking for pkl files to copy..."
        echo "Today's suffix: $TODAY"
        
        # List available files
        echo "Files in ../pkbrokers/kite/examples/results/Data/:"
        ls -la ../pkbrokers/kite/examples/results/Data/ 2>/dev/null || echo "Directory not found"
        
        # Copy pkl files - try both date-suffixed and generic names
        FILES_COPIED=0
        
        # Daily pkl files
        for PKL_FILE in ../pkbrokers/kite/examples/results/Data/stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/daily_candles.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
            if [ "$PKL_SIZE" -gt 1000000 ]; then
              echo "✅ Found: $PKL_FILE ($PKL_SIZE bytes)"
              cp "$PKL_FILE" actions-data-download/stock_data_${TODAY}.pkl
              cp "$PKL_FILE" actions-data-download/daily_candles.pkl
              FILES_COPIED=$((FILES_COPIED + 1))
              break
            else
              echo "⚠️ File too small: $PKL_FILE ($PKL_SIZE bytes)"
            fi
          fi
        done
        
        # Intraday pkl files - try to generate from ticks.json if not present
        INTRADAY_FOUND=0
        for PKL_FILE in ../pkbrokers/kite/examples/results/Data/intraday_stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/intraday_1m_candles.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
            if [ "$PKL_SIZE" -gt 10000 ]; then
              echo "✅ Found intraday: $PKL_FILE ($PKL_SIZE bytes)"
              cp "$PKL_FILE" actions-data-download/intraday_stock_data_${TODAY}.pkl
              cp "$PKL_FILE" actions-data-download/intraday_1m_candles.pkl
              FILES_COPIED=$((FILES_COPIED + 1))
              INTRADAY_FOUND=1
              break
            fi
          fi
        done
        
        # If no intraday pkl, try to generate from ticks.json
        if [ "$INTRADAY_FOUND" -eq 0 ]; then
          echo "No intraday pkl found, trying to generate from ticks.json..."
          cd ../pkbrokers/kite/examples/
          python3 ../../../pkbrokers/scripts/generate_pkl_from_ticks.py --data-dir results/Data --verbose 2>/dev/null || true
          cd -
          
          # Check again for intraday pkl
          for PKL_FILE in ../pkbrokers/kite/examples/results/Data/intraday_stock_data_*.pkl ../pkbrokers/kite/examples/results/Data/intraday_1m_candles.pkl; do
            if [ -f "$PKL_FILE" ]; then
              PKL_SIZE=$(stat -c%s "$PKL_FILE" 2>/dev/null || stat -f%z "$PKL_FILE")
              if [ "$PKL_SIZE" -gt 10000 ]; then
                echo "✅ Generated intraday: $PKL_FILE ($PKL_SIZE bytes)"
                cp "$PKL_FILE" actions-data-download/intraday_stock_data_${TODAY}.pkl
                cp "$PKL_FILE" actions-data-download/intraday_1m_candles.pkl
                FILES_COPIED=$((FILES_COPIED + 1))
                break
              fi
            fi
          done
        fi
        
        # DO NOT copy .db files - they are too large for GitHub (>100MB limit)
        # The database is only used locally for generating pkl files
        echo "Note: SQLite .db files are not committed (too large for GitHub)"
        
        echo "Total files copied: $FILES_COPIED"
        
        # Commit and push
        git config user.name "github-actions[bot]"
        git config user.email "actions@github.com"
        
        # Remove any .db files that may have been accidentally copied (too large for GitHub)
        rm -f actions-data-download/*.db 2>/dev/null || true
        
        # Only add pkl and json files (no .db files - they exceed GitHub's 100MB limit)
        git add -f actions-data-download/*.pkl 2>/dev/null || true
        git add -f actions-data-download/*.json 2>/dev/null || true
        
        # Show what's staged
        echo "Files to be committed:"
        git diff --staged --name-only
        
        if ! git diff --staged --quiet; then
          git commit -m "Update pkl files from history download - $TODAY [period: ${{ inputs.period }}]"
          
          # Retry push with rebase if needed
          for i in 1 2 3; do
            if git push; then
              echo "✅ Successfully committed updated pkl files to PKScreener actions-data-download"
              break
            else
              echo "Push failed, attempt $i, pulling and retrying..."
              git pull --rebase origin actions-data-download || true
              sleep 2
            fi
          done
        else
          echo "No changes to commit"
        fi

    - name: Send notification about the completion
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ inputs.period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully finished child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

  trigger-next-child-job:
    needs: [historical-data]
    if: (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    timeout-minutes: 358
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || 20 }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Determine next period
      id: next-period
      run: |
        CURRENT_PERIOD="${{ github.event.inputs.period }}"
        echo "Current period: $CURRENT_PERIOD"
        
        case "$CURRENT_PERIOD" in
            "day")
                NEXT_PERIOD="minute"
                ;;
            "minute")
                NEXT_PERIOD="5minute"
                ;;
            "5minute")
                NEXT_PERIOD="10minute"
                ;;
            "10minute")
                NEXT_PERIOD="30minute"
                ;;
            "30minute")
                NEXT_PERIOD="60minute"
                ;;
            "60minute")
                echo "✅ All periods completed. Exiting."
                echo "should_exit=true" >> $GITHUB_OUTPUT
                exit 0
                ;;
            *)
                # Default to starting from day if no period specified
                NEXT_PERIOD="day"
                ;;
        esac
        
        echo "Next period: $NEXT_PERIOD"
        echo "next_period=$NEXT_PERIOD" >> $GITHUB_OUTPUT
        echo "should_exit=false" >> $GITHUB_OUTPUT

    - name: Create .env.dev file with secrets
      env:
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ inputs.kiteToken || secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: ${{ secrets.DB_TYPE }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
        PERIOD: ${{ inputs.period }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        TBTOKEN=$TBTOKEN
        PERIOD=$PERIOD
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file for period: day"

    - name: Exit if all periods completed
      if: steps.next-period.outputs.should_exit == 'true'
      run: |
        echo "✅ All periods have been processed. Workflow completed."
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        pip install pkdevtools
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ All periods for historical data jobs have been processed. Workflow completed.');"
        exit 0

    - name: Trigger next child job
      if: steps.next-period.outputs.should_exit == 'false'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
      run: |
        NEXT_PERIOD="${{ steps.next-period.outputs.next_period }}"
        echo "Triggering next child job for period: $NEXT_PERIOD"
        
        LOG_LEVEL="${{ github.event.inputs.logLevel || '20' }}"
        KITE_TOKEN="${{ github.event.inputs.kiteToken || secrets.KTOKEN }}"
        
        # Trigger child workflow for the next period only
        curl -X POST \
          -H "Authorization: token $GITHUB_TOKEN" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/actions/workflows/w1-workflow-history-data-child.yml/dispatches" \
          -d "{\"ref\":\"main\",\"inputs\":{\"period\":\"$NEXT_PERIOD\",\"logLevel\":\"$LOG_LEVEL\",\"kiteToken\":\"$KITE_TOKEN\",\"pastoffset\":\"${{ github.event.inputs.pastoffset || 0 }}\"}}"
        
        echo "✅ Successfully triggered next child job for period: $NEXT_PERIOD"

    - name: Send notification about the trigger
      shell: bash
      env:
          THIS_KITE_PERIOD : ${{ steps.next-period.outputs.next_period }}
          THIS_KITE_TOKEN: ${{ github.event.inputs.kiteToken || secrets.KTOKEN }}
      run: |
        pip install pkdevtools
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python3 -c "import os; from PKDevTools.classes.Telegram import send_message; send_message('✅ Successfully triggered child job with valid Kite token:(' + os.environ['THIS_KITE_TOKEN'] + ') for period: '+os.environ['THIS_KITE_PERIOD']+'\n');"

    - name: Log completion
      run: |
        echo "Next period job triggered successfully. Workflow will continue with the next period in the chain."
