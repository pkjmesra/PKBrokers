# """
#     The MIT License (MIT)

#     Copyright (c) 2023 pkjmesra

#     Permission is hereby granted, free of charge, to any person obtaining a copy
#     of this software and associated documentation files (the "Software"), to deal
#     in the Software without restriction, including without limitation the rights
#     to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#     copies of the Software, and to permit persons to whom the Software is
#     furnished to do so, subject to the following conditions:

#     The above copyright notice and this permission notice shall be included in all
#     copies or substantial portions of the Software.

#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#     OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#     SOFTWARE.

# """
name: 0. 24x7 bot Ticks Runner
on:
  schedule:
    # Every 5 hours and 50 minutes
    - cron: '50 */5 * * *'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      logLevel:
        description: 'Log level for PKDevTools (default 20)'
        required: false
        default: 20
        type: number

jobs:
  market-runner:
    runs-on: ubuntu-latest
    timeout-minutes: 355  # Just under 6 hours (5h55m) to avoid being cutoff
    env:
      PKDevTools_Default_Log_Level: ${{ github.event.inputs.logLevel || '20' }}
      TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
    
    steps:
    - name: Checkout PKBrokers code
      uses: actions/checkout@v4
      with:
        repository: pkjmesra/PKBrokers
        ref: main

    # - name: Check for holidays
    #   id: holiday_check
    #   run: |
    #     # Download the holidays JSON file
    #     curl -s -o holidays.json https://raw.githubusercontent.com/pkjmesra/PKScreener/main/.github/dependencies/nse-holidays.json
        
    #     # Get current date in DD-MMM-YYYY format (e.g., 26-Jan-2025)
    #     CURRENT_DATE=$(date +"%d-%b-%Y")
        
    #     # Check if current date is in holidays list
    #     if jq -e --arg date "$CURRENT_DATE" '.CM[] | select(.tradingDate == $date)' holidays.json > /dev/null; then
    #       echo "Today ($CURRENT_DATE) is a market holiday. Exiting."
    #       echo "is_holiday=true" >> $GITHUB_OUTPUT
    #     else
    #       echo "Today ($CURRENT_DATE) is not a market holiday. Proceeding."
    #       echo "is_holiday=false" >> $GITHUB_OUTPUT
    #     fi

    # - name: Exit if holiday (scheduled runs only)
    #   if: github.event_name == 'schedule' && steps.holiday_check.outputs.is_holiday == 'true'
    #   run: |
    #     echo "Skipping execution due to market holiday."
    #     exit 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Restore pip cache
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-pkbrokers-${{ hashFiles('**/setup.py', '**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-pkbrokers-
          ${{ runner.os }}-pip-

    - name: Install PKBrokers dependencies
      run: |
        pip install -e .
        pip install kiteconnect

    - name: Create .env.dev file with secrets
      env:
        # Map all PKBrokers related secrets to environment variables
        CHAT_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
        chat_idADMIN: ${{ secrets.chat_idADMIN }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        CI_PAT: ${{ secrets.CI_PAT }}
        TURSO_TOKEN: ${{ secrets.TURSO_TOKEN }}
        TDU: ${{ secrets.TDU }}
        TAT: ${{ secrets.TAT }}
        MCU: ${{ secrets.MCU }}
        MCAP: ${{ secrets.MCAP }}
        MCL: ${{ secrets.MCL }}
        MS: ${{ secrets.MS }}
        PKG: ${{ secrets.PKG }}
        REPO_URL: ${{ secrets.REPO_URL }}
        KTOKEN: ${{ secrets.KTOKEN }}
        KUSER: ${{ secrets.KUSER }}
        KPWD: ${{ secrets.KPWD }}
        KTOTP: ${{ secrets.KTOTP }}
        DB_TYPE: "local"
        DB_TICKS: ${{ secrets.DB_TICKS }}
        TBTOKEN: ${{ secrets.TBTOKEN }}
        BBTOKEN: ${{ secrets.BBTOKEN }}
        Tel_API_ID: ${{ secrets.Tel_API_ID }}
        Tel_API_Hash: ${{ secrets.Tel_API_Hash }}
        Tel_Phone_Number: ${{ secrets.Tel_Phone_Number }}
        TEL_SESSION_DATA: ${{ secrets.TEL_SESSION_DATA }}
      run: |
        cat > .env.dev << EOF
        CHAT_ID=$CHAT_ID
        TOKEN=$TOKEN
        chat_idADMIN=$chat_idADMIN
        GITHUB_TOKEN=$GITHUB_TOKEN
        CI_PAT=$CI_PAT
        TURSO_TOKEN=$TURSO_TOKEN
        TDU=$TDU
        TAT=$TAT
        MCU=$MCU
        MCAP=$MCAP
        MCL=$MCL
        MS=$MS
        PKG=$PKG
        REPO_URL=$REPO_URL
        KTOKEN=$KTOKEN
        KUSER=$KUSER
        KPWD=$KPWD
        KTOTP=$KTOTP
        DB_TYPE=$DB_TYPE
        DB_TICKS=$DB_TICKS
        TBTOKEN=$TBTOKEN
        BBTOKEN=$BBTOKEN
        Tel_API_ID=$Tel_API_ID
        Tel_API_Hash=$Tel_API_Hash
        Tel_Phone_Number=$Tel_Phone_Number
        TEL_SESSION_DATA=$TEL_SESSION_DATA
        PKDevTools_Default_Log_Level=${{ env.PKDevTools_Default_Log_Level }}
        EOF
        
        echo "Created .env.dev file with secrets"
        echo "Set PKDevTools_Default_Log_Level to ${{ env.PKDevTools_Default_Log_Level }}"

    - name: Create session file
      run: |
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        echo ${{ env.TEL_SESSION_DATA }} | base64 -d > user_session.session
        chmod 600 user_session.session

    - name: Run pkkite orchestrator from source
      env:
        PYTHONUNBUFFERED: 1  # Force unbuffered output
        PKDevTools_Default_Log_Level: ${{ env.PKDevTools_Default_Log_Level }}
      run: |
        # Run pkkite directly from the source module
        echo "Running pkkite --orchestrate from PKBrokers source..."
        pwd
        cp .env.dev pkbrokers/kite/examples/.env.dev
        cd pkbrokers/kite/examples/
        python pkkite.py --orchestrate --verbose 2>&1 | while IFS= read -r line; do
          # Print timestamp with each log line for better debugging
          echo "[$(date '+%Y-%m-%d %H:%M:%S')] $line"
        done
        
        EXIT_CODE=${PIPESTATUS[0]}
        echo "pkkite exited with code $EXIT_CODE"

    - name: Convert ticks.json to pkl if needed
      if: always()
      run: |
        echo "Checking if pkl files need to be generated from ticks.json..."
        
        DATA_DIR="pkbrokers/kite/examples/results/Data"
        TICKS_JSON_1="$DATA_DIR/ticks.json"
        TICKS_JSON_2="pkbrokers/kite/examples/ticks.json"
        DATE_SUFFIX=$(date +%d%m%Y)
        
        # Check if pkl files exist
        PKL_EXISTS=false
        if [ -f "$DATA_DIR/intraday_1m_candles.pkl" ] || [ -f "$DATA_DIR/intraday_stock_data_${DATE_SUFFIX}.pkl" ]; then
          PKL_EXISTS=true
          echo "Intraday pkl files already exist"
        fi
        
        # If no pkl files, convert from ticks.json
        if [ "$PKL_EXISTS" = false ]; then
          echo "No pkl files found, attempting to convert ticks.json..."
          
          # Find ticks.json
          if [ -f "$TICKS_JSON_1" ] && [ -s "$TICKS_JSON_1" ]; then
            TICKS_JSON="$TICKS_JSON_1"
          elif [ -f "$TICKS_JSON_2" ] && [ -s "$TICKS_JSON_2" ]; then
            TICKS_JSON="$TICKS_JSON_2"
          else
            echo "No ticks.json found to convert"
            exit 0
          fi
          
          echo "Converting $TICKS_JSON to pkl..."
          
          cd pkbrokers/kite/examples
          python3 << CONVERT_SCRIPT
        import os
        import json
        import pickle
        from datetime import datetime
        import pandas as pd

        ticks_json = "$TICKS_JSON".replace("pkbrokers/kite/examples/", "")
        if not ticks_json.startswith("/"):
            ticks_json = os.path.basename(ticks_json)
            for p in ["results/Data/ticks.json", "ticks.json"]:
                if os.path.exists(p):
                    ticks_json = p
                    break

        print(f"Loading ticks from: {ticks_json}")

        with open(ticks_json, 'r') as f:
            ticks_data = json.load(f)

        print(f"Found {len(ticks_data)} instruments in ticks.json")

        data = {}
        for token_str, tick_info in ticks_data.items():
            try:
                symbol = tick_info.get('trading_symbol', str(token_str))
                ohlcv = tick_info.get('ohlcv', {})
                
                if not ohlcv or ohlcv.get('close', 0) <= 0:
                    continue
                
                timestamp_str = ohlcv.get('timestamp', '')
                if timestamp_str:
                    try:
                        dt = pd.to_datetime(timestamp_str)
                    except:
                        dt = datetime.now()
                else:
                    dt = datetime.now()
                
                df = pd.DataFrame([{
                    'Date': dt,
                    'Open': float(ohlcv.get('open', 0)),
                    'High': float(ohlcv.get('high', 0)),
                    'Low': float(ohlcv.get('low', 0)),
                    'Close': float(ohlcv.get('close', 0)),
                    'Volume': int(ohlcv.get('volume', 0)),
                }])
                df.set_index('Date', inplace=True)
                data[symbol] = df
            except Exception as e:
                continue

        if data:
            os.makedirs('results/Data', exist_ok=True)
            today = datetime.now().strftime('%d%m%Y')
            
            # Save intraday pkl
            pkl_path = f'results/Data/intraday_stock_data_{today}.pkl'
            with open(pkl_path, 'wb') as f:
                pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            size_mb = os.path.getsize(pkl_path) / (1024 * 1024)
            print(f"Saved {len(data)} instruments to {pkl_path} ({size_mb:.2f} MB)")
            
            # Also save as generic name
            with open('results/Data/intraday_1m_candles.pkl', 'wb') as f:
                pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
            print("Also saved as intraday_1m_candles.pkl")
        else:
            print("No valid data to convert")
        CONVERT_SCRIPT
          cd ../../..
        fi

    - name: Push ticks and pkl files to PKScreener
      if: always()
      env:
        GH_TOKEN: ${{ secrets.CI_PAT }}
      run: |
        echo "Checking for files to push to PKScreener..."
        
        # Define paths - check multiple locations
        # The kiteTokenWatcher saves to results/Data relative to cwd (pkbrokers/kite/examples/)
        # So files end up in pkbrokers/kite/examples/results/Data/
        TICKS_PATH_1="pkbrokers/kite/examples/results/Data/ticks.json"
        TICKS_PATH_2="pkbrokers/kite/examples/ticks.json"
        DATA_DIR_1="pkbrokers/kite/examples/results/Data"
        DATA_DIR_2="pkbrokers/kite/examples"
        DATE_SUFFIX=$(date +%d%m%Y)
        
        # Find ticks.json
        if [ -f "$TICKS_PATH_1" ] && [ -s "$TICKS_PATH_1" ]; then
          TICKS_PATH="$TICKS_PATH_1"
        else
          TICKS_PATH="$TICKS_PATH_2"
        fi
        
        # Find DATA_DIR with pkl files
        if [ -d "$DATA_DIR_1" ]; then
          DATA_DIR="$DATA_DIR_1"
        else
          DATA_DIR="$DATA_DIR_2"
        fi
        
        echo "Using TICKS_PATH: $TICKS_PATH"
        echo "Using DATA_DIR: $DATA_DIR"
        
        # Clone PKScreener
        echo "Cloning PKScreener actions-data-download branch..."
        git clone --depth 1 --branch actions-data-download https://x-access-token:${GH_TOKEN}@github.com/pkjmesra/PKScreener.git pkscreener-data || {
          echo "Branch doesn't exist, cloning main and creating branch..."
          git clone --depth 1 https://x-access-token:${GH_TOKEN}@github.com/pkjmesra/PKScreener.git pkscreener-data
          cd pkscreener-data && git checkout -b actions-data-download && cd ..
        }
        
        mkdir -p pkscreener-data/results/Data
        mkdir -p pkscreener-data/actions-data-download
        
        FILES_COPIED=0
        
        # Copy ticks.json if exists
        if [ -f "$TICKS_PATH" ] && [ -s "$TICKS_PATH" ]; then
          TICKS_SIZE=$(stat -c%s "$TICKS_PATH" 2>/dev/null || stat -f%z "$TICKS_PATH")
          echo "Found ticks.json ($TICKS_SIZE bytes)"
          
          if [ "$TICKS_SIZE" -gt 10 ]; then
            cp "$TICKS_PATH" pkscreener-data/results/Data/ticks.json
            FILES_COPIED=$((FILES_COPIED + 1))
          fi
        fi
        
        # Copy daily pkl files
        for PKL_FILE in "$DATA_DIR"/daily_candles.pkl "$DATA_DIR"/stock_data_*.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_NAME=$(basename "$PKL_FILE")
            echo "Found $PKL_NAME"
            cp "$PKL_FILE" pkscreener-data/actions-data-download/
            FILES_COPIED=$((FILES_COPIED + 1))
          fi
        done
        
        # Copy intraday pkl files
        for PKL_FILE in "$DATA_DIR"/intraday_1m_candles.pkl "$DATA_DIR"/intraday_stock_data_*.pkl; do
          if [ -f "$PKL_FILE" ]; then
            PKL_NAME=$(basename "$PKL_FILE")
            echo "Found $PKL_NAME"
            cp "$PKL_FILE" pkscreener-data/actions-data-download/
            FILES_COPIED=$((FILES_COPIED + 1))
          fi
        done
        
        # Copy SQLite DB files
        for DB_FILE in "$DATA_DIR"/candles_*.db; do
          if [ -f "$DB_FILE" ]; then
            DB_NAME=$(basename "$DB_FILE")
            echo "Found $DB_NAME"
            cp "$DB_FILE" pkscreener-data/actions-data-download/
            FILES_COPIED=$((FILES_COPIED + 1))
          fi
        done
        
        if [ "$FILES_COPIED" -gt 0 ]; then
          # Create metadata
          cat > pkscreener-data/results/Data/ticks_metadata.json << EOF
        {
          "source": "PKBrokers-orchestrator",
          "synced_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "workflow": "w0-workflow-ticks-update.yml",
          "files_copied": $FILES_COPIED,
          "date_suffix": "$DATE_SUFFIX"
        }
        EOF
          
          cd pkscreener-data
          git config user.name "github-actions[bot]"
          git config user.email "actions@github.com"
          # Use -f to force add files that may be in .gitignore
          git add -f results/Data/ actions-data-download/ 2>/dev/null || true
          
          if git diff --staged --quiet; then
            echo "No changes to push"
          else
            git commit -m "Sync ticks and pkl from PKBrokers $(date -u +%Y-%m-%dT%H:%M:%SZ)"
            
            # Retry logic for push conflicts
            for i in 1 2 3; do
              if git push origin actions-data-download; then
                echo "âœ… Files pushed to PKScreener successfully ($FILES_COPIED files)"
                break
              else
                echo "Push failed, attempt $i, pulling and retrying..."
                git pull --rebase origin actions-data-download || true
                sleep 2
              fi
            done
          fi
          cd ..
        else
          echo "No files to push"
        fi

    - name: Cleanup .env.dev file
      if: always()
      run: |
        echo "Cleaning up .env.dev file"
        rm -f .env.dev
        
    - name: Delete history of workflow runs
      shell: bash
      run: |
        gh run list --status completed --limit 100 --json databaseId -q '.[].databaseId' | xargs -IID gh api "repos/$(gh repo view --json nameWithOwner -q .nameWithOwner)/actions/runs/ID" -X DELETE
        gh run list --status cancelled --limit 100 --json databaseId -q '.[].databaseId' | xargs -IID gh api "repos/$(gh repo view --json nameWithOwner -q .nameWithOwner)/actions/runs/ID" -X DELETE
      env:
        GH_TOKEN : ${{secrets.GITHUB_TOKEN}}